{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:159: UserWarning: pylab import has clobbered these variables: ['norm']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "\n",
    "# The first time you run this might be a bit slow, since the\n",
    "# mnist package has to download and cache the data.\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "\n",
    "print(train_images.shape) # (60000, 28, 28)\n",
    "print(train_labels.shape) # (60000,)\n",
    "\n",
    "# gradient between 0 and 1 for 256*256\n",
    "array = np.linspace(0,1,256*256)\n",
    "\n",
    "# reshape to 2d\n",
    "#mat = np.reshape(train_images[1],(256,256))\n",
    "\n",
    "# Creates PIL image\n",
    "img = Image.fromarray(train_images[1], \"L\")\n",
    "#new_image = img.resize((400,400))\n",
    "enhancer2 = ImageEnhance.Contrast(img)\n",
    "new_image = enhancer2.enhance(1)\n",
    "enhancer1 = ImageEnhance.Sharpness(new_image)\n",
    "new_image = enhancer1.enhance(100)\n",
    "new_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "\n",
    "# Normalize the images.\n",
    "train_images = (train_images / 255)\n",
    "test_images = (test_images / 255)\n",
    "\n",
    "# Reshape the images.\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "test_images = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "print(train_images.shape) # (60000, 28, 28, 1)\n",
    "print(test_images.shape)  # (10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4792 - accuracy: 0.8600 - val_loss: 0.2730 - val_accuracy: 0.9176\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2428 - accuracy: 0.9278 - val_loss: 0.2004 - val_accuracy: 0.9423\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1983 - accuracy: 0.9415 - val_loss: 0.1855 - val_accuracy: 0.9464\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_filters = 8\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "\n",
    "model = Sequential([\n",
    "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1), strides=2, padding='same', activation='relu'),\n",
    "  MaxPooling2D(pool_size=pool_size),\n",
    "  Flatten(),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  'adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  epochs=3,\n",
    "  validation_data=(test_images, to_categorical(test_labels)),\n",
    ")\n",
    "model.save_weights('cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13376/2486940635.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cnn.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Predict on the first 5 test images.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.load_weights('cnn.h5')\n",
    "\n",
    "# Predict on the first 5 test images.\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "# Print our model's predictions.\n",
    "#print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "#print(test_labels) # [7, 2, 1, 0, 4]\n",
    "sum = 0\n",
    "#for i in range(len(predictions)):\n",
    "    #if (predictions[i] == test_labels[i]).all():\n",
    "        #sum += 1\n",
    "#sum / len(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.03994112 9.62592623 0.9862387  2.88660973 2.57920283 9.15633371\n",
      " 0.29481945 7.83192071 8.26013099 4.04754924]\n",
      "18.51091709546645\n",
      "[0.11020206 0.52001347 0.05327876 0.15594094 0.13933415 0.49464506\n",
      " 0.01592679 0.42309739 0.44623024 0.21865741]\n"
     ]
    }
   ],
   "source": [
    "an_array = np.random.rand(10)*10\n",
    "print(an_array)\n",
    "\n",
    "norm = np.linalg.norm(an_array)\n",
    "print(norm)\n",
    "normal_array = an_array/norm\n",
    "print(normal_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homogeneous(X):\n",
    "    return np.insert(X, 0, values=1, axis=-1)\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, input_size=None, output_size=None):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.prev = None\n",
    "        self.next = None\n",
    "    def __call__(self, callable_graph):\n",
    "        self.prev = callable_graph\n",
    "        callable_graph.next = self\n",
    "        self.input_size = callable_graph.output_size\n",
    "        if self.output_size is None:\n",
    "            self.output_size = self.input_size\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.forward(X) if self.next is None else self.next.predict(self.forward(X))\n",
    "    \n",
    "    def bakcdrop(self, Y):\n",
    "        return self.backward(Y) if self.prev is None else self.prev.backdrop(self.backward(Y))\n",
    "\n",
    "    def str_chain(self):\n",
    "        return str(self) if self.next is None else str(self) + \" -> \" + self.next.str_chain()\n",
    "    \n",
    "class Dense(Layer):\n",
    "    def __init__(self, units, input_size=None):\n",
    "        Layer.__init__(self, input_size, units)\n",
    "        self.W = None\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.W = np.random.normal(0, scale=2/(self.input_size), size=(self.output_size, self.input_size + 1))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        if self.W is None:\n",
    "            self.init_weights()\n",
    "        \n",
    "        Xh = homogeneous(X)\n",
    "        self.last_inputs = Xh\n",
    "\n",
    "        return self.W.dot(Xh.T)\n",
    "\n",
    "    def backward(self, Y):\n",
    "        input_3d = np.swapaxes(np.expand_dims(self.last_inputs, axis=0), 0, 1)\n",
    "        y_t_3d = np.transpose(np.swapaxes(np.expand_dims(Y, axis=0), 0, 1), (0,2,1))\n",
    "        self.grad = np.mean(y_t_3d * input_3d, axis=0)\n",
    "\n",
    "        back_error = self.W.dot(Y.T)\n",
    "        return np.delete(back_error)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Dense(\" + str(self.input_size) + \", \" + str(self.output_size) + \")\"\n",
    "    \n",
    "class ReLU(Layer):\n",
    "    def forward(self, X):\n",
    "        self.last_input = X # Save inputs for backpropagation\n",
    "        return np.maximum(X, 0)\n",
    "\n",
    "    def backward(self, Y):\n",
    "        return Y * np.maximum(np.sign(self.last_input), 0)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"ReLU(\" + str(self.input_size) + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13]\n",
      " [23]]\n"
     ]
    }
   ],
   "source": [
    "inputs = Dense(64, input_size=1)\n",
    "x = inputs\n",
    "x = ReLU()(x)\n",
    "x = Dense(64)(x)\n",
    "x = ReLU()(x)\n",
    "x = Dense(1)(x)\n",
    "outputs = x\n",
    "\n",
    "inputs.str_chain()\n",
    "print(np.dot(np.array([[2,3],[4,5]]), np.array([[2],[3]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21336/3888915462.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Forward step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mYp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Compute error and output gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "\n",
    "for i in range(40000):\n",
    "\n",
    "    # Forward step\n",
    "    Yp = inputs.predict(X)\n",
    "\n",
    "    # Compute error and output gradient\n",
    "    dE = Yp - Y\n",
    "    E = np.mean(dE ** 2)\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(\"MSE:\", E)\n",
    "\n",
    "    if E < 0.001: # If MSE is small, stop\n",
    "        print(\"MSE:\", E)\n",
    "        break\n",
    "\n",
    "    # Backprop\n",
    "    outputs.backprop(dE)\n",
    "\n",
    "     # Update the weights (layer.W) for every trainable layer using the gradient (layer.grad)\n",
    "    current_layer = inputs\n",
    "    while current_layer is not None:\n",
    "      if isinstance(current_layer, Dense):\n",
    "        current_layer.W -= current_layer.grad * lr\n",
    "      current_layer = current_layer.next\n",
    "\n",
    "plt.scatter(X, Y)\n",
    "plt.plot(Xr, inputs.predict(Xr))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
